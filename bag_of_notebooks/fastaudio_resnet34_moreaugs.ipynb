{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"fastaudio_resnet34_moreaugs.ipynb","provenance":[{"file_id":"1zvp5l0s4jd710QNxwUM_Kxim5l5z7z5-","timestamp":1611821545175}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ULx_xUCpR-yo","executionInfo":{"status":"ok","timestamp":1612774549562,"user_tz":-180,"elapsed":27458,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"84ff8e5f-841e-4989-9993-6ab21b0a36b5"},"source":["!sudo apt install -y libsndfile1\n","!pip install numba==0.48\n","!pip install git+https://github.com/fastaudio/fastaudio.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libsndfile1 is already the newest version (1.0.28-4ubuntu0.18.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n","Collecting numba==0.48\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/7f/dbe85f5f419dca88509d829df90dfa5aefa39c39f6b7020dfc206a386279/numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5MB)\n","\u001b[K     |████████████████████████████████| 3.5MB 5.3MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (53.0.0)\n","Collecting llvmlite<0.32.0,>=0.31.0dev0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n","\u001b[K     |████████████████████████████████| 20.2MB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (1.19.5)\n","\u001b[31mERROR: umap-learn 0.5.0 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pynndescent 0.5.1 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n","Installing collected packages: llvmlite, numba\n","  Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","Successfully installed llvmlite-0.31.0 numba-0.48.0\n","Collecting git+https://github.com/fastaudio/fastaudio.git\n","  Cloning https://github.com/fastaudio/fastaudio.git to /tmp/pip-req-build-1lq528sv\n","  Running command git clone -q https://github.com/fastaudio/fastaudio.git /tmp/pip-req-build-1lq528sv\n","Collecting fastai==2.1.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/55/53a6e59561f97e6b2699e665d587aaf1502ea1efc428e17e17a1a7e23af1/fastai-2.1.9-py3-none-any.whl (190kB)\n","\u001b[K     |████████████████████████████████| 194kB 4.3MB/s \n","\u001b[?25hCollecting torchaudio>=0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/f9/618434cf4e46dc975871e1516f5499abef6564ab4366f9b2321ee536be14/torchaudio-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 34.9MB/s \n","\u001b[?25hRequirement already satisfied: librosa==0.8 in /usr/local/lib/python3.6/dist-packages (from fastaudio==0.1.4.post0.dev2+g8631a3f) (0.8.0)\n","Collecting colorednoise>=1.1\n","  Downloading https://files.pythonhosted.org/packages/a3/3e/85645bcaa5ba6003c6e3c650fe23c6352f7aa4a36eb1d700f3609e52963e/colorednoise-1.1.1.tar.gz\n","Collecting IPython>=7.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/6a/210816c943c9aeeb29e4e18a298f14bf0e118fe222a23e13bfcc2d41b0a4/ipython-7.16.1-py3-none-any.whl (785kB)\n","\u001b[K     |████████████████████████████████| 788kB 49.6MB/s \n","\u001b[?25hCollecting fastcore==1.3.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ad/7c358331783cf8220e1bd0cca52df3e6092b3f6d4ce5b837fffbc9a64c53/fastcore-1.3.12-py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.13)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.22.2.post1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.7.0+cu101)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.2.2)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.1.5)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.2.4)\n","Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (19.3.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.23.0)\n","Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (7.0.0)\n","Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.6/dist-packages (from fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.8.1+cu101)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.0.0)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.3.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.19.5)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.2.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.48.0)\n","Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.10.3.post1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.1.9)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (53.0.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/f4/805f4596bf15ae8e576623f579b40c12b0780a7bdd9a437f205f136d9ece/prompt_toolkit-3.0.14-py3-none-any.whl (359kB)\n","\u001b[K     |████████████████████████████████| 368kB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.6.1)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.18.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (4.3.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (4.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.3.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2018.9)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.8.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.0.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (4.41.1)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.4.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (2020.12.5)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.4.4)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from resampy>=0.2.2->librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.15.0)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.31.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (1.14.4)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.2.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.8.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=7.13->fastaudio==0.1.4.post0.dev2+g8631a3f) (0.7.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.4.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8->fastaudio==0.1.4.post0.dev2+g8631a3f) (2.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.1.9->fastaudio==0.1.4.post0.dev2+g8631a3f) (3.4.0)\n","Building wheels for collected packages: fastaudio, colorednoise\n","  Building wheel for fastaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastaudio: filename=fastaudio-0.1.4.post0.dev2+g8631a3f-py2.py3-none-any.whl size=18329 sha256=c790b8af0190cc88138efbc2bea1cd9bd8b53fcef0003eebef43828822bae69a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vzidrl2h/wheels/20/af/b1/ea2a6d91971f5e3f435c6a0aa2ae8b7a010b644cc01e24b0ce\n","  Building wheel for colorednoise (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for colorednoise: filename=colorednoise-1.1.1-cp36-none-any.whl size=3958 sha256=4ed0b831470b2d63f590f2c74f1ba4ef309aeff22fd076920a3e9b8669a89bf7\n","  Stored in directory: /root/.cache/pip/wheels/84/be/f3/3e7e1c80ebab3f6f0dbd3e34e787b902d2280d66706485fef4\n","Successfully built fastaudio colorednoise\n","\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.14 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.16.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchaudio 0.7.2 has requirement torch==1.7.1, but you'll have torch 1.7.0+cu101 which is incompatible.\u001b[0m\n","Installing collected packages: fastcore, fastai, torchaudio, colorednoise, prompt-toolkit, IPython, fastaudio\n","  Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","  Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","Successfully installed IPython-7.16.1 colorednoise-1.1.1 fastai-2.1.9 fastaudio-0.1.4.post0.dev2+g8631a3f fastcore-1.3.12 prompt-toolkit-3.0.14 torchaudio-0.7.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jnyma5fkuA6A","executionInfo":{"status":"ok","timestamp":1612774556189,"user_tz":-180,"elapsed":34076,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"21480486-e192-4b13-dbc1-30901b0e9751"},"source":["!pip install timm\n","!pip install efficientnet_pytorch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting timm\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/ba02d533cec7329323c7d7a317ab49f673846ecef202d4cc40988b6b7786/timm-0.3.4-py3-none-any.whl (244kB)\n","\r\u001b[K     |█▍                              | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 133kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 143kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 153kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 163kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 174kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 184kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 194kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 204kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 215kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 225kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.0+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.1+cu101)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n","Installing collected packages: timm\n","Successfully installed timm-0.3.4\n","Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.7.0+cu101)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16032 sha256=1a59615aba1c24eed5cf44e42c5c30fdd565bb59c08823888aa82f7e9c1d0383\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E798_JhkR-y_","executionInfo":{"status":"ok","timestamp":1612774842176,"user_tz":-180,"elapsed":1286,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puKPWfwVR-zA","executionInfo":{"status":"ok","timestamp":1612774845034,"user_tz":-180,"elapsed":4125,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"2bc34fe3-5052-495f-f6c3-9fcbc2d50e65"},"source":["import torchaudio\n","torchaudio.set_audio_backend(\"sox_io\")\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n","  '\"sox\" backend is being deprecated. '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tvpx5YenR-zB","executionInfo":{"status":"ok","timestamp":1612774847022,"user_tz":-180,"elapsed":6108,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"fdddc0c6-9b27-48ac-9847-5f456a2e845d"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import sys\n","sys.path.append(\"..\")\n","\n","import librosa as lr\n","import librosa.display\n","\n","import soundfile as sf\n","import io\n","\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","\n","from fastaudio.core.all import *\n","from fastaudio.augment.all import *\n","from fastai.torch_basics import *\n","from fastai.basics import *\n","from fastai.data.all import *\n","from fastai.callback.all import *\n","from fastai.vision.all import *\n","\n","import fastai\n","fastai.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.1.8'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"byHiKwd1J4-8","executionInfo":{"status":"ok","timestamp":1612774867991,"user_tz":-180,"elapsed":27071,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"fab7099f-cbae-44f4-b97a-40ddb41a50dd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')# You must grant COLAB access to your Google Drive"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"ZFkobKPoR-zB","executionInfo":{"status":"ok","timestamp":1612774884407,"user_tz":-180,"elapsed":43482,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"94b247d1-f6e3-4f2a-d630-1bd4cfb02887"},"source":["DATA_ROOT = Path(\"/content/drive/MyDrive/Colab Notebooks/RainForestAudio/data\")\n","AUDIO_ROOT = Path(DATA_ROOT/\"train/\")\n","TRAIN_AUDIO_ROOT = Path(DATA_ROOT/\"samples_center\")\n","#TRAIN_AUDIO_ROOT = Path(\"/content/samples_long\")\n","#TRAIN_AUDIO_ROOT = Path(DATA_ROOT/\"samples_mixed\")\n","TEST_AUDIO_ROOT = Path(DATA_ROOT/\"test\")\n","VAL_AUDIO_ROOT = Path(DATA_ROOT/\"val\")\n","df_train = pd.DataFrame([path.stem for path in Path(TRAIN_AUDIO_ROOT).glob(\"*.flac\")], columns=[\"recording_id\"])\n","train_folds = np.load(Path(DATA_ROOT/\"folds.npy\"), allow_pickle=True)\n","df_test = pd.DataFrame([path.stem for path in Path(TEST_AUDIO_ROOT).glob(\"*.flac\")], columns=[\"recording_id\"])\n","df = pd.read_csv(Path(DATA_ROOT/\"train_tp.csv\"))\n","print(df_train.shape, df_test.shape)\n","df"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(1216, 1) (0, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>recording_id</th>\n","      <th>species_id</th>\n","      <th>songtype_id</th>\n","      <th>t_min</th>\n","      <th>f_min</th>\n","      <th>t_max</th>\n","      <th>f_max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003bec244</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>44.5440</td>\n","      <td>2531.250</td>\n","      <td>45.1307</td>\n","      <td>5531.25</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>006ab765f</td>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>39.9615</td>\n","      <td>7235.160</td>\n","      <td>46.0452</td>\n","      <td>11283.40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>007f87ba2</td>\n","      <td>12</td>\n","      <td>1</td>\n","      <td>39.1360</td>\n","      <td>562.500</td>\n","      <td>42.2720</td>\n","      <td>3281.25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0099c367b</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>51.4206</td>\n","      <td>1464.260</td>\n","      <td>55.1996</td>\n","      <td>4565.04</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>009b760e6</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>50.0854</td>\n","      <td>947.461</td>\n","      <td>52.5293</td>\n","      <td>10852.70</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1211</th>\n","      <td>fe8d9ac40</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>53.4720</td>\n","      <td>93.750</td>\n","      <td>54.0960</td>\n","      <td>843.75</td>\n","    </tr>\n","    <tr>\n","      <th>1212</th>\n","      <td>fea6b438a</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>43.5787</td>\n","      <td>2531.250</td>\n","      <td>45.7653</td>\n","      <td>4031.25</td>\n","    </tr>\n","    <tr>\n","      <th>1213</th>\n","      <td>ff2eb9ce5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>15.2267</td>\n","      <td>5906.250</td>\n","      <td>16.0213</td>\n","      <td>8250.00</td>\n","    </tr>\n","    <tr>\n","      <th>1214</th>\n","      <td>ffb8d8391</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>14.3467</td>\n","      <td>4781.250</td>\n","      <td>16.6987</td>\n","      <td>10406.20</td>\n","    </tr>\n","    <tr>\n","      <th>1215</th>\n","      <td>ffb9a7b9a</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>40.3200</td>\n","      <td>3187.500</td>\n","      <td>41.0133</td>\n","      <td>5062.50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1216 rows × 7 columns</p>\n","</div>"],"text/plain":["     recording_id  species_id  songtype_id  ...     f_min    t_max     f_max\n","0       003bec244          14            1  ...  2531.250  45.1307   5531.25\n","1       006ab765f          23            1  ...  7235.160  46.0452  11283.40\n","2       007f87ba2          12            1  ...   562.500  42.2720   3281.25\n","3       0099c367b          17            4  ...  1464.260  55.1996   4565.04\n","4       009b760e6          10            1  ...   947.461  52.5293  10852.70\n","...           ...         ...          ...  ...       ...      ...       ...\n","1211    fe8d9ac40          13            1  ...    93.750  54.0960    843.75\n","1212    fea6b438a           4            1  ...  2531.250  45.7653   4031.25\n","1213    ff2eb9ce5           0            1  ...  5906.250  16.0213   8250.00\n","1214    ffb8d8391           5            1  ...  4781.250  16.6987  10406.20\n","1215    ffb9a7b9a          18            1  ...  3187.500  41.0133   5062.50\n","\n","[1216 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"vedRqZlR7L-4"},"source":["# Define multi class model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVWvGZv1LOE4","executionInfo":{"status":"ok","timestamp":1612774884408,"user_tz":-180,"elapsed":43477,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"02a4b055-d735-43ea-a374-2916addbfcdc"},"source":["def get_y_fn(x):\n","  y = str(x).split(\".\")[0].split('_')[-2]\n","  return y\n","\n","FOLD = 4\n","val_index = train_folds[FOLD]\n","FOLD = str(FOLD)\n","val_index"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([469, 492, 494, 512, 515, 532, 533, 539, 542, 545, 547, 551, 555,\n","       556, 563, 565, 567, 571, 572, 573, 574, 576, 580, 581, 582, 585,\n","       586, 587, 588, 589, 591, 592, 594, 595, 596, 597, 599, 603, 604,\n","       605, 606, 607, 609, 610, 613, 617, 618, 619, 620, 621, 622, 623,\n","       625, 627, 628, 629, 631, 632, 633, 634, 635, 637, 638, 639, 640,\n","       641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653,\n","       654, 655, 656, 657, 658, 659, 660, 661, 663, 664, 665, 666, 667,\n","       668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n","       681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n","       694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706,\n","       707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719,\n","       720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n","       733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n","       746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758,\n","       759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771,\n","       772, 773, 774, 775, 824, 826, 828, 829, 830, 831, 832, 871, 872,\n","       873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 934, 935, 937,\n","       942, 946, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959,\n","       960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8-aYX03_IRV","executionInfo":{"status":"ok","timestamp":1612774884409,"user_tz":-180,"elapsed":43474,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"e86f7199-fe86-44b2-d337-0661268b6cc2"},"source":["train_folds[0].shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(240,)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"WGGZLJuaTmd6"},"source":["## define mixup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJdJEY12Tl4-","executionInfo":{"status":"ok","timestamp":1612774886291,"user_tz":-180,"elapsed":45351,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"c5104964-5761-4c68-a073-b33bb0f6ee11"},"source":["!git clone https://github.com/nestordemeure/ManifoldMixupV2.git"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Cloning into 'ManifoldMixupV2'...\n","remote: Enumerating objects: 370, done.\u001b[K\n","remote: Counting objects: 100% (370/370), done.\u001b[K\n","remote: Compressing objects: 100% (186/186), done.\u001b[K\n","remote: Total 370 (delta 202), reused 347 (delta 181), pack-reused 0\u001b[K\n","Receiving objects: 100% (370/370), 651.94 KiB | 960.00 KiB/s, done.\n","Resolving deltas: 100% (202/202), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxN6SwtbTsld","executionInfo":{"status":"ok","timestamp":1612774888744,"user_tz":-180,"elapsed":47800,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"332c64a2-3c36-4e70-bbe3-43377b5e8a59"},"source":["%run /content/ManifoldMixupV2/manifold_mixup.py\n","OutputMixup()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OutputMixup"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"CQc9Jo_wDCPv"},"source":["## Define db and dls"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI_0-L4N3ldB","executionInfo":{"status":"ok","timestamp":1612774890984,"user_tz":-180,"elapsed":50037,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}},"outputId":"91f4e292-0b48-443c-dfb6-408075b83960"},"source":["!git clone https://NadyaStrogankova:c12ca00be6ebdcb705be6f0e9fac559a684c3d3b@github.com/NadyaStrogankova/RainforestAudioKaggle.git"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Cloning into 'RainforestAudioKaggle'...\n","remote: Enumerating objects: 19, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 19 (delta 7), reused 10 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (19/19), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rf8Z7C_P3oID","executionInfo":{"status":"ok","timestamp":1612774890985,"user_tz":-180,"elapsed":50037,"user":{"displayName":"Nadya Strogankova","photoUrl":"","userId":"11793698916100822526"}}},"source":["%run /content/RainforestAudioKaggle/transforms.py"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaxZGk-1R-zS","outputId":"91d4acb3-a266-472a-814d-d838f139d8bf"},"source":["cfg = AudioConfig.BasicMelSpectrogram(\n","        mel=True,\n","  #      to_db = False\n","        f_min=df[\"f_min\"].min(),\n","        f_max=df[\"f_max\"].max(),\n","        # n_fft=1024,\n","        n_mels=384,\n","        hop_length=292,\n","       # n_fft = 892, \n","        #hop_length=245, \n","        #n_mels = 224,\n","      #  normalized=True\n","   )\n","\n","item_tfms = [Resample(28000),\n","             ResizeSignal(8000, pad_mode=AudioPadType.Repeat), \n","            AddNoise(noise_level=0.05, color=NoiseColor.Pink),\n","            AddNoise(noise_level=0.05, color=NoiseColor.White),\n","           ]\n","batch_tfms = [ AudioToSpec.from_cfg(cfg), \n","       #       Normalize_channel(),\n","       #       PowerSpec(), # увеличение контрастности\n","       #       TAmplitudeToDB(),\n","              Normalize_channel_1(),\n","    #          PowerSpec(1.5, 0.7),\n","              WhiteNoise(0.005, cfg),\n","              PinkNoise(0.005, cfg),\n","       #       RowNoise(0.025, cfg),\n","              LowerUpperFreq(cfg),\n","              Normalize_channel_2(),\n","              PowerSpec(2, 0.7), # увеличение контрастности\n","      #        Normalize_channel_3(),\n","              SGRoll(),\n","              Mask(),\n","           #   Mono2Color()\n","         #     Normalize(ch_mean, ch_std, axes=(0, 1, 3)),\n","              ]\n","AddNoise.split_idx = 0\n","Mask.split_idx = 0\n","\n","SGRoll.split_idx = 0\n","\n","auds = DataBlock(blocks = (AudioBlock, CategoryBlock),  \n","                 get_items=get_audio_files,\n","                 item_tfms = item_tfms,\n","                 splitter = IndexSplitter(val_index.tolist()), #report unnesesary transform to list\n","                 #splitter = RandomSplitter(),\n","                 get_y=get_y_fn,\n","                 batch_tfms = batch_tfms\n","                                  )\n","print(auds.summary(TRAIN_AUDIO_ROOT))\n","dls = auds.dataloaders(TRAIN_AUDIO_ROOT, bs=24, verbose=True, before_batch = batch_tfms, \n","                       num_workers=2\n","                       #, shuffle=True\n","                      )\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setting-up type transforms pipelines\n","Collecting items from /content/drive/MyDrive/Colab Notebooks/RainForestAudio/data/samples_center\n","Found 1216 items\n","2 datasets of sizes 971,245\n","Setting up Pipeline: partial\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchaudio/functional.py:318: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (384) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n","  \"At least one mel filterbank has all zero values. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Setting up Pipeline: get_y_fn -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n","\n","Building one sample\n","  Pipeline: partial\n","    starting from\n","      /content/drive/MyDrive/Colab Notebooks/RainForestAudio/data/samples_center/2cd09cfab_11_216.flac\n","    applying partial gives\n","      AudioTensor of size 1x141042\n","  Pipeline: get_y_fn -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n","    starting from\n","      /content/drive/MyDrive/Colab Notebooks/RainForestAudio/data/samples_center/2cd09cfab_11_216.flac\n","    applying get_y_fn gives\n","      11\n","    applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives\n","      TensorCategory(3)\n","\n","Final sample: (AudioTensor([[ 0.0007,  0.0044,  0.0007,  ...,  0.0029, -0.0031, -0.0004]]), TensorCategory(3))\n","\n","\n","Collecting items from /content/drive/MyDrive/Colab Notebooks/RainForestAudio/data/samples_center\n","Found 1216 items\n","2 datasets of sizes 971,245\n","Setting up Pipeline: partial\n","Setting up Pipeline: get_y_fn -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}\n","Setting up after_item: Pipeline: Resample -> DownmixMono -> ResizeSignal -> AddNoise -> ToTensor\n","Setting up before_batch: Pipeline: \n","Setting up after_batch: Pipeline: AudioToSpec -> Normalize_channel_1 -> WhiteNoise -> PinkNoise -> LowerUpperFreq -> Normalize_channel_2 -> PowerSpec -> SGRoll -> Mask -> IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O3e_04_DZKaq"},"source":["def _one_sample_positive_class_precisions(scores, truth):\n","    num_classes = scores.shape[0]\n","    pos_class_indices = np.flatnonzero(truth > 0)\n","\n","    if not len(pos_class_indices):\n","        return pos_class_indices, np.zeros(0)\n","\n","    retrieved_classes = np.argsort(scores)[::-1]\n","\n","    class_rankings = np.zeros(num_classes, dtype=np.int)\n","    class_rankings[retrieved_classes] = range(num_classes)\n","\n","    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n","    retrieved_class_true[class_rankings[pos_class_indices]] = True\n","\n","    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n","\n","    precision_at_hits = (\n","            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n","            (1 + class_rankings[pos_class_indices].astype(np.float)))\n","    return pos_class_indices, precision_at_hits\n","\n","def lwlrap(scores, truth):\n","    #print(truth.shape, scores.shape)\n","    num_samples, num_classes = scores.shape\n","    scores = scores.cpu().numpy()\n","    gt = np.zeros((num_samples, num_classes))\n","    for n, i in enumerate(truth.cpu().numpy().astype(int)):\n","      gt[n, i] = 1\n","    assert gt.shape == scores.shape\n","    \n","    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n","    for sample_num in range(num_samples):\n","        pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(scores[sample_num, :], gt[sample_num, :])\n","        precisions_for_samples_by_classes[sample_num, pos_class_indices] = precision_at_hits\n","\n","    labels_per_class = np.sum(gt > 0, axis=0)\n","    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n","\n","    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n","                        np.maximum(1, labels_per_class))\n","    #return per_class_lwlrap, weight_per_class\n","    return (per_class_lwlrap * weight_per_class).sum()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-HyUhFNhvlw"},"source":["from efficientnet_pytorch import EfficientNet\n","from timm import create_model\n","# from https://colab.research.google.com/github/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/05_EfficientNet_and_Custom_Weights.ipynb#scrollTo=VXPjDVUlJgCU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewC-e6U0uHDi"},"source":["def create_timm_body(arch:str, pretrained=True, cut=None):\n","  model = create_model(arch, pretrained=pretrained, in_chans=1)\n","  if cut is None:\n","    ll = list(enumerate(model.children()))\n","    cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n","  if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n","  elif callable(cut): return cut(model)\n","  else: raise NamedError(\"cut must be either integer or function\")\n","body = create_timm_body('resnest50_fast_1s1x64d', pretrained=True)\n","body =  create_timm_body('resnet34', pretrained=True, cut=-2)\n","#head = create_head(num_features_model(nn.Sequential(*body.children())) * (2), dls.c)\n","head = create_head(512, dls.c, concat_pool=False, ps=0.4)\n","model = nn.Sequential(body, head)\n","apply_init(model[1], nn.init.kaiming_normal_)\n","len(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMvV_yrz509E"},"source":["model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeYflMxtR-zS"},"source":["learn = Learner(dls,  model,\n","           # n_in=1, #<- Only audio specific modification here\n","        #    loss_func=LabelSmoothingCrossEntropyFlat(),\n","            cbs = OutputMixup(alpha=0.4),\n","            metrics=[accuracy, lwlrap])\n","learn.to_fp16()\n","learn.loss_func"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xb5wZcjKIIJ8"},"source":["dls.show_batch(), dls.vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EEWc0D-R-zT"},"source":["#learn.lr_find()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VAxjc5_O2nd"},"source":["#wdc wc  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U5gS61f2fSYO"},"source":["EXP_NAME = \"rn34_fold\" + FOLD \n","SUFFIX =\"step1\"\n","learn.freeze()\n","learn.fit(3, 1e-3/2)\n","learn.unfreeze()\n","base_lr = 1e-3/2\n","learn.fit_one_cycle(25, slice(base_lr / 2, base_lr * 2), wd=1e-2, div=10, div_final=1e+2, pct_start=0.3,\n","                    cbs=[SaveModelCallback(fname = f'{EXP_NAME}_{SUFFIX}', with_opt=True)]\n","                    )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"986JzSZPhJNF"},"source":["SUFFIX =\"step2\"\n","learn.load(EXP_NAME+\"_step1\")\n","base_lr = base_lr / 4\n","learn.fit_one_cycle(24, slice(base_lr / 4, base_lr * 4), wd=1e-2, div=10, div_final=1e+2, pct_start=0.3,\n","                    cbs=[SaveModelCallback(fname = f'{EXP_NAME}_{SUFFIX}', with_opt=True)]\n","                    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4-B1Shji-lx"},"source":["SUFFIX =\"step3\"\n","#learn.load(EXP_NAME+\"_step2\")\n","base_lr = 1e-3/2\n","base_lr = base_lr / 8\n","learn.fit_one_cycle(25, slice(base_lr / 2, base_lr * 2), wd=1e-2, div=10, div_final=1e+2, pct_start=0.3,\n","                    cbs=[SaveModelCallback(fname = f'{EXP_NAME}_{SUFFIX}', with_opt=True)]\n","                    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R96dpPgZ_l-C"},"source":["# SUFFIX =\"step4\"\n","# #learn.load(EXP_NAME+\"_step2\")\n","# base_lr = 1e-3/2\n","# base_lr = base_lr / 16\n","# learn.fit_one_cycle(25, slice(base_lr / 2, base_lr * 2), wd=1e-2, div=10, div_final=1e+2, pct_start=0.3,\n","#                     cbs=[SaveModelCallback(fname = f'{EXP_NAME}_{SUFFIX}', with_opt=True)]\n","#                     )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0mDWQ-eJTEe"},"source":["# SUFFIX =\"step5\"\n","# #learn.load(EXP_NAME+\"_step2\")\n","# base_lr = 1e-3/2\n","# base_lr = base_lr / 32\n","# learn.fit_one_cycle(25, slice(base_lr / 2, base_lr * 2), wd=1e-2, div=10, div_final=1e+2, pct_start=0.3,\n","#                     cbs=[SaveModelCallback(fname = f'{EXP_NAME}_{SUFFIX}', with_opt=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oYuAzydi7sNv"},"source":["## confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"_EAhQY4p7YLx"},"source":["# Predict all classes"]},{"cell_type":"code","metadata":{"id":"lx9-pVnNUuT6"},"source":["learn.load(\"rn34_fold\"+FOLD+\"_step1\", with_opt=False)\n","learn.remove_cbs(OutputMixup)\n","learn.cbs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_N8zoCoknR8h"},"source":["interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_confusion_matrix()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFMZcAnefQSR"},"source":["#!ln -s drive/MyDrive/Colab\\ Notebooks/RainForestAudio/data/ol_samples.tar.gz ol_samples.tar.gz  \n","#!ln -s drive/MyDrive/Colab\\ Notebooks/RainForestAudio/data/val  val\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OurWFYgnAMiG"},"source":["#!tar -xf ol_samples.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mlgz3NW6x3Iz"},"source":["TEST_SAMPLES_AUDIO_ROOT = Path(\"/content/samples\")\n","\n","#!ln -s drive/MyDrive/Colab\\ Notebooks/RainForestAudio/data/val/ /content/val\n","VAL_AUDIO_ROOT = Path(\"/content/val\")\n","\n","test_ds = auds.new(VAL_AUDIO_ROOT)\n","test_dl = learn.dls.test_dl(get_audio_files(TEST_SAMPLES_AUDIO_ROOT))\n","#print(test_dl.summary(TEST_TARGET_AUDIO_ROOT))\n","#test_probas, *_ = learn.tta(dl=test_dl, n=2, use_max=True)\n","test_probas, *_ = learn.tta(dl=test_dl, n=6, use_max=False, beta=1/7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tGOuDrT5kjG"},"source":["result=[]\n","for probas, fname in zip(test_probas, test_dl.items):\n","  print(fname)\n","  result.append([fname.stem.split(\"_\")[0], fname.stem.split(\"_\")[1], probas.numpy()])\n","res = pd.DataFrame(result, columns =[\"recording_id\", \"part_id\", \"probas\"])\n","res[\"part_id\"] = res[\"part_id\"].astype(int)\n","res.to_csv(\"all_class_pred_\"+FOLD+\".csv\", columns =[\"recording_id\", \"part_id\", \"probas\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFMycFCou8Fj"},"source":["subm = []\n","for n, row in res.sort_values(by=\"recording_id\").groupby(by=\"recording_id\"):\n","  a = np.stack(row[\"probas\"].values)\n","  pred = np.concatenate([np.array(n).reshape(1),\n","                         np.array(dls.vocab[np.argmax(a.max(axis=0))]).reshape(1),\n","                         #np.where(a>0.7, a, 0).sum(axis=0)\n","                         a.max(axis=0)\n","                         ])\n","  subm.append(pred)\n","  #print(n)\n","  if n == \"047a7c4bf\":\n","    #print(row[\"probas\"].max(axis=1))\n","    cls = np.stack(row[\"probas\"].values).max(axis=0).argsort()\n","    #print(np.stack(row[\"probas\"].values).argsort())\n","    #print(dls.vocab[cls[-1]], dls.vocab[cls[-2]], dls.vocab[cls[-3]])\n","#print(subm)\n","submission = pd.DataFrame(subm, columns=[\"recording_id\"] + [\"top_cat\"] + [\"s\" + i for i in dls.vocab])\n","submission.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNaDxF9i9BxC"},"source":["submission.drop([\"top_cat\"], axis=1, inplace=True)\n","submission.to_csv(\"subm_29_fold_\"+FOLD+\"_0.csv\", columns=[\"recording_id\"] + [\"s\" + str(i) for i in range(24)], index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYoGVIKpkuYD"},"source":["from sklearn.metrics import accuracy_score\n","gt=[]\n","pred=[]\n","for n, row in submission.iterrows():\n","  try:\n","    gr_tr = df[df[\"recording_id\"] == row[\"recording_id\"]][\"species_id\"].to_numpy()\n","    if gr_tr.shape[0] > 1:\n","      if int(row[\"top_cat\"]) in gr_tr:\n","        gt.append(int(row[\"top_cat\"]))\n","      else:\n","        gt.append(gr_tr[0])     \n","    else: \n","      gt.append(gr_tr[0])\n","    pred.append(int(row[\"top_cat\"]))\n","  except:\n","    pass\n","accuracy_score(gt,pred), len(gt)\n","#gt, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWqKOZozzgqK"},"source":["Усредненный сабмит"]},{"cell_type":"code","metadata":{"id":"QJt4s3ATzfmP"},"source":["subm = []\n","#subm.append(submission.sort_values(by=\"recording_id\").to_numpy()[:,1:].astype(float))\n","for i in range(4):\n","  s = pd.read_csv(\"subm_29_fold_\"+str(i)+\"_0.csv\")\n","  subm.append(s.sort_values(by=\"recording_id\").to_numpy()[:,1:])\n","subm = np.stack(subm)\n","subm.shape\n","fs = pd.DataFrame(np.concatenate([submission.sort_values(by=\"recording_id\").to_numpy()[:,0].reshape(-1,1), subm.sum(axis=0)], axis=1),  columns=s.columns)\n","fs.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snvvT4mb3UOj"},"source":["fs.to_csv(\"subm_29_rn34.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQ5_0kSlzfpn"},"source":["!tar -cf rn_34_weigth_2901.tar models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuC4LH7HLFUp"},"source":["!cp rn_34_weigth_2901.tar /content/drive/MyDrive/Colab\\ Notebooks/RainForestAudio"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAdoQTK_zJeH"},"source":["## Вспомогательное\n"]},{"cell_type":"code","metadata":{"id":"va90ifjuZnBf"},"source":["class MaskFreq_fixed(SpectrogramTransform):\n","    \"\"\"Google SpecAugment frequency masking from https://arxiv.org/abs/1904.08779.\"\"\"\n","\n","    def __init__(self, num_masks=1, size=20, start=None, val=None):\n","        self.num_masks = num_masks\n","        self.size = size\n","        self.start = start\n","        self.val = val\n","\n","    def encodes(self, sg: AudioSpectrogram) -> AudioSpectrogram:\n","        channel_mean = sg.contiguous().view(sg.size(0), -1).mean(-1)[:, None, None]\n","        mask_val = ifnone(self.val, channel_mean)\n","        if sg.ndim == 4:\n","          b, c, y, x = sg.shape\n","          # Position of the first mask\n","          start = ifnone(self.start, random.randint(0, y - self.size))\n","          for _ in range(self.num_masks):\n","              mask = torch.ones(self.size, x).cuda() * mask_val.cuda()\n","              mask = mask.view(b, c, self.size, x)\n","              #print(\"sg, mask:\", sg.shape, mask.shape)\n","              if not 0 <= start <= y - self.size:\n","                  raise ValueError(\n","                      f\"Start value '{start}' out of range for AudioSpectrogram of shape {sg.shape}\"\n","                  )\n","              sg[:, :, start : start + self.size, :] = mask\n","              # Setting start position for next mask\n","              start = random.randint(0, y - self.size)\n","        else:\n","          c, y, x = sg.shape\n","          # Position of the first msk\n","          start = ifnone(self.start, random.randint(0, y - self.size))\n","          for _ in range(self.num_masks):\n","              mask = torch.ones(self.size, x) * mask_val\n","              if not 0 <= start <= y - self.size:\n","                  raise ValueError(\n","                      f\"Start value '{start}' out of range for AudioSpectrogram of shape {sg.shape}\"\n","                  )\n","              sg[:, start : start + self.size, :] = mask\n","              # Setting start position for next mask\n","              start = random.randint(0, y - self.size)\n","        return sg"],"execution_count":null,"outputs":[]}]}